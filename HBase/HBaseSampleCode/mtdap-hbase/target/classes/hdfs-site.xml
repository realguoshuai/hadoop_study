<?xml version="1.0" encoding="UTF-8"?><configuration>
<property>
<name>ipc.server.tcpnodelay</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>1048576</value>
</property>
<property>
<name>ipc.25000.faircallqueue.priority-levels</name>
<value>4</value>
</property>
<property>
<name>iostat.interval</name>
<value>600</value>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/home/omm/.ssh/id_rsa</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.1</value>
</property>
<property>
<name>dfs.namenode.audit.log.async</name>
<value>false</value>
</property>
<property>
<name>dfs.balancer.auto.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.ha.zkfc.port</name>
<value>25015</value>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.session-timeout.ms</name>
<value>45000</value>
</property>
<property>
<name>ipc.server.handler.queue.size</name>
<value>100</value>
</property>
<property>
<name>dfs.namenode.journalnode</name>
<value>guoshuai3:25012;guoshuai2:25012;guoshuai1:25012</value>
</property>
<property>
<name>dfs.namenode.audit.log.debug.cmdlist</name>
<value>open,getfileinfo,listStatus,getAclStatus</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>guoshuai3:24002,guoshuai2:24002,guoshuai1:24002</value>
</property>
<property>
<name>backup.meta.zk.parent-znode</name>
<value>/hdfs-backup</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>3</value>
</property>
<property>
<name>dfs.nodetag.tagloader.interval</name>
<value>10000</value>
</property>
<property>
<name>dfs.blockplacement.mandatory.rackgroup.name</name>
<value></value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.namenode.http.policy</name>
<value>HTTP_ONLY</value>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.63</name>
<value>guoshuai2:25003</value>
</property>
<property>
<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.path.based.cache.block.map.allocation.percent</name>
<value>0.25f</value>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>true</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>guoshuai3:24002,guoshuai2:24002,guoshuai1:24002</value>
</property>
<property>
<name>dfs.rackgroup.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault</value>
</property>
<property>
<name>hadoop.proxyuser.miner.groups</name>
<value>*</value>
</property>
<property>
<name>ipc.server.read.threadpool.size</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
</property>
<property>
<name>dfs.balancer.auto.excluded.paths</name>
<value></value>
</property>
<property>
<name>dfs.balancer.auto.exclude.datanodes</name>
<value></value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.229</name>
<value>guoshuai3:25005</value>
</property>
<property>
<name>backup.worker.implement.multi-thread.num</name>
<value>3</value>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTP_ONLY</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.replication.interval</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.http.port</name>
<value>25002</value>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
</property>
<property>
<name>dfs.client.io-weight</name>
<value>10</value>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/FusionInsight-HDFS/dn_socket</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.lock.limit</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>64</value>
</property>
<property>
<name>dfs.qjournal.write-txns.timeout.ms</name>
<value>20000</value>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>0</value>
</property>
<property>
<name>dfs.replication.max</name>
<value>512</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.auto.data.mover.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>true</value>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
</property>
<property>
<name>oi.dfs.colocation.balancer.exclude.block.policy.class</name>
<value>com.huawei.hadoop.oi.colocation.PathPatternBasedExcludeBlockPolicy</value>
</property>
<property>
<name>dfs.balancer.auto.policy</name>
<value>datanode</value>
</property>
<property>
<name>iostat.enabled</name>
<value>false</value>
</property>
<property>
<name>ipc.25000.callqueue.impl</name>
<value>java.util.concurrent.LinkedBlockingQueue</value>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.count</name>
<value></value>
</property>
<property>
<name>dfs.balancer.auto.threshold</name>
<value>10</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>0.5f</value>
</property>
<property>
<name>dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction</name>
<value>0.6</value>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>262144</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>1000000</value>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>0.999999</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
<property>
<name>dfs.hosts</name>
<value></value>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["63","229"]}]</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.63</name>
<value>guoshuai2:25005</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>64</value>
</property>
<property>
<name>dfs.namenode.replication.considerLoad</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.file.close.num-committed-allowed</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.reconstruction.pending.timeout-sec</name>
<value>900</value>
</property>
<property>
<name>ipc.server.max.response.size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>
<property>
<name>backup.meta.zk.quorum</name>
<value>guoshuai3:24002,guoshuai2:24002,guoshuai1:24002</value>
</property>
<property>
<name>backup.split.size</name>
<value>1073741824</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>10</value>
</property>
<property>
<name>ipc.25000.backoff.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.balancer.auto.include.datanodes</name>
<value></value>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.229</name>
<value>guoshuai3:25003</value>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
</property>
<property>
<name>dfs.image.loader.thread</name>
<value>0</value>
</property>
<property>
<name>hadoop.http.authentication.cookie.domain</name>
<value></value>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>128</value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
</property>
<property>
<name>dfs.auto.data.mover.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>3600000</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-bind-host</name>
<value>guoshuai2</value>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.plugins</name>
<value></value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.thresholds</name>
<value></value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc.port</name>
<value>25005</value>
</property>
<property>
<name>net.topology.nodegroup.aware</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60</value>
</property>
<property>
<name>dfs.federation.datanode</name>
<value>guoshuai5:25008,guoshuai4:25008,guoshuai3:25008,guoshuai6:25008,guoshuai2:25008,guoshuai1:25008</value>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>10000</value>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>7999</value>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>10</value>
</property>
<property>
<name>dfs.ha.fencing.methods</name>
<value>shell(/bin/true)</value>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
</property>
<property>
<name>dfs.cluster.administrators</name>
<value>hdfs supergroup,System_administrator_186</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>DEFAULT</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.algorithm</name>
<value>3des</value>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.decay-factor</name>
<value>0.5</value>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.period-ms</name>
<value>5000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.63</name>
<value>guoshuai2:25000</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>63,229</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.229</name>
<value>guoshuai3:25002</value>
</property>
<property>
<name>dfs.namenode.replication.considerLoad.io-load</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.https.port</name>
<value>25003</value>
</property>
<property>
<name>dfs.namenode.inode.attributes.provider.class</name>
<value>com.huawei.hadoop.adapter.hdfs.plugin.HWINodeAttributeProvider</value>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>3600</value>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>supergroup</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
</property>
<property>
<name>dfs.block.replicator.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
</property>
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://${dfs.namenode.journalnode}/hacluster</value>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.image.loader.inode.partition</name>
<value>1048576</value>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120</value>
</property>
<property>
<name>ipc.25000.faircallqueue.multiplexer.weights</name>
<value></value>
</property>
<property>
<name>dfs.namenode.io.load.balance.reading.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.ha.namenode.id</name>
<value>63</value>
</property>
<property>
<name>oi.dfs.colocation.file.pattern</name>
<value></value>
</property>
<property>
<name>dfs.nodelabel.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.rpc.port</name>
<value>25000</value>
</property>
<property>
<name>ipc.25000.identity-provider.impl</name>
<value>org.apache.hadoop.ipc.UserIdentityProvider</value>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>15000</value>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>false</value>
</property>
<property>
<name>dfs.nodetag.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault</value>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.63</name>
<value>guoshuai2:25002</value>
</property>
<property>
<name>dfs.datanode.lifeline.interval.seconds</name>
<value></value>
</property>
<property>
<name>dfs.support.append</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
</property>
<property>
<name>dfs.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.229</name>
<value>guoshuai3:25000</value>
</property>
<property>
<name>audit.service.name</name>
<value>HDFS</value>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>3600</value>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>true</value>
</property>
</configuration>
