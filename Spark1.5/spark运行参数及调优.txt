# 套牌车分析
nohup spark-submit \
--class com.guoshuai.mtdap.realtime.FakeVehicle  \
--name MTDAP_FakeVehicle \
--jars $SPARK_HOME/lib/streamingClient/kafka-clients-0.8.2.1.jar,$SPARK_HOME/lib/streamingClient/kafka_2.10-0.8.2.1.jar,$SPARK_HOME/lib/streamingClient/spark-streaming-kafka_2.10-1.5.1.jar,$SPARK_HOME/lib/streamingClient/phoenix-core-4.4.0-HBase-1.0.jar,$SPARK_HOME/lib/streamingClient/jredisclient-0.0.1.jar,$SPARK_HOME/lib/streamingClient/commons-pool2-2.3.jar \
--executor-memory 2G \
--num-executors 2 \
--executor-cores 1 \
--driver-cores 1 \
--driver-memory 2G \
/opt/MtdapProgram/realtime/mtdap-rtf-fakevehicle-1.0/mtdap-rtf-fakevehicle-1.0.jar >/opt/MtdapProgram/realtime/mtdap-rtf-fakevehicle-1.0/mtdap-rtf-fakevehicle.log 2>&1 &


# 参数调优

executor-memory
	该参数用于设置每个Executor进程的内存,Executor内存的大小,很多时候直接决定了Spark作业的性能,而且跟常见的JVM OOM异常,也有直接的关联。
	每个Executor进程的内存设置4G~8G较为合适.每个程序在不同环境下配置不是固定的
	需要根据所有程序的总资源进行调整,过多会占用其他程序的资源,影响其他程序运行
	num-executors乘以executor-memory，是不能超过队列的最大内存量的
	
num-executors
	几个executor执行
executor-cores
	这个参数决定每个executor占用的CPU 内核数,决定每个executor并行执行的task的能力
	原因:每个CPU的core同一时间只能执行一个task线程
	2-4个较合适,需要根据运行环境的cores总数决定,一般不要超过总队列的1/3-1/2
driver-memory
	该参数用于设置Driver进程的内存
	默认1G ,但是如果使用collect算子将数据全部拉取到Driver上来处理,就必须保证Driver的内存够大,否则OOM
--conf 配置时使用自定义的运行 而不是使用/conf目录下的文件
spark.default.parallelism
	eg:--conf spark.default.parallelism=1000 \
	默认500-1000个比较合适
	设置该参数为num-executors * executor-cores的2~3倍 ,比如总的CPU core数量300,设置1000个可行
	
spark.storage.memoryFraction
	如果才WebUI页面发现 gc的手机速度特别慢 ,就意味着task执行用户代码的内存不够用,调低这个参数